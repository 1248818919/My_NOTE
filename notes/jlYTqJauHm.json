{"_id":"note:jlYTqJauHm","title":"TrackFormer","content":"# TrackFormer\n\nMeinhardt T, Kirillov A, Leal-Taixe L, et al. Trackformer: Multi-object tracking with transformers[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 8844-8854.\n\n## 1.abstract\n\n多目标跟踪(MOT)是一项具有挑战性的任务，需要同时对目标轨迹的初始化、检测目标身份检测和目标时空轨迹的关联这三个任务进行推理。本文将此任务表述为帧到帧之间的预测问题，并提出了一种新的模型Trackformer。这是一种基于编码器-解码器Transformer架构的端到端可训练的MOT方法。该模型通过视频序列预测出一组轨迹预测，通过关注实现帧之间的数据关联。Transformer解码器从static object queries开始初始化新的轨道，并使用track queries在空间和时间上自动回归地跟踪现有的轨道。这两种查询类型都受益于自注意力以及编码器-解码器对全局帧级特征的关注，从而省去了任何额外的图形优化或运动和/或外观建模。Trackformer引入了一种新的关注跟踪范式，虽然其设计简单，但能够在多目标跟踪(MOT17和MOT20)和分割(MOTS20)任务上实现最先进的性能。\n\n## 2.Method\n\n","tags":[],"folderPathname":"/Computer Vision/Track/single_view","data":{},"createdAt":"2024-04-01T09:17:15.761Z","updatedAt":"2024-04-01T09:26:52.662Z","trashed":false,"_rev":"X8f5HSDNg"}