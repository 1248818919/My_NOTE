{"_id":"note:XdzUGvM1CY","title":"CVGL","content":"# CVGl 论文阅读笔记\n\nFervers F, Bullinger S, Bodensteiner C, et al. Uncertainty-aware Vision-based Metric Cross-view Geolocalization[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 21621-21631.\n\n## 1.Introduction\n\n自动驾驶系统既需要车辆的环境模型，也需要车辆相对于模型的位置。这些系统要么在运行时构建完整的模型(即完全在线)，要么在运行时之前创建一些部分(即部分离线)。后一种方法通常是提前构建一个地区的高清地图(例如使用激光雷达传感器)，并在运行时相对于该地图定位车辆[34]。虽然以前的地图有助于提高系统的定位精度，但它们的构建和维护成本也很高。另一方面，在线方法仅使用实时传感器读数创建本地环境模型，例如来自激光雷达[52]，摄像头[15]或两者[26]。这避免了对昂贵的预先地图的需要，但代表了一个更困难的任务，因为系统必须预测环境的空间结构及其在其中的相对位置。\n\n- 我们提出了一种新的端到端可训练的度量CVGL模型，它只需要视觉输入并产生不确定性感知预测。\n- 我们从几个正射影像提供商那里收集了多个车辆数据集和航空图像，用于我们的评估。我们使用伪标签方法计算改进的地面真态姿态，并通过数据修剪过滤掉无效样本。\n- 我们的方法优于以前的工作，即使在严格更具挑战性的跨区域和跨车辆设置。\n\n\n","tags":[],"folderPathname":"/Computer Vision/Geo-localization","data":{},"createdAt":"2024-01-13T02:20:09.639Z","updatedAt":"2024-01-13T02:34:38.681Z","trashed":false,"_rev":"eDkriDrar"}