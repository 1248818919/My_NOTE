{"_id":"note:s3lbrRta71","title":"ARO","content":"# ARO 阅读笔记\n\n> Yuksekgonul M, Bianchi F, Kalluri P, et al. When and why vision-language models behave like bags-of-words, and what to do about it?[C]//The Eleventh International Conference on Learning Representations. 2023.\n\n## 1.Abstract\n\n尽管在许多下游任务中使用了大型视觉和语言模型(vlm)，但它们如何很好地编码对象和属性之间的组合关系还不清楚。因此，本文创建了属性、关系和顺序(Attribution, Relation, and Order, ARO)基准，以系统地评估vlm理解不同类型的关系、属性和顺序信息的能力。ARO包括Visual Genome Attribution，用于测试对物体属性的理解;Visual Genome Relation，测试关系理解;以及COCO-Order和Flickr30k-Order，用于测试VLMs的顺序灵敏度。ARO比以前的组合性基准测试要大几个数量级，有超过50,000个测试用例。本文介绍了最先进的vlm的设置，在这些设置中，最先进的vlm表现得像袋子一样。当他们没有很好的关系理解时，在将对象与其属性链接时可能会出错，并且表现出严重缺乏顺序敏感性。\n\nvlm主要是在具有丰富的图像和字幕组成结构的大规模数据集上进行训练和评估的。因此，在这些数据集上的训练还不足以解决对构图理解的缺乏，对这些数据集的评估也未能解决这一缺陷。为了理解为什么这些限制会出现并且没有在标准测试中表现出来，我们将重点放在培训和评估过程中。我们证明，在不使用组合和顺序信息的情况下，可以在现有数据集上很好地执行图像文本检索。这进一步激发了使用ARO对vlm进行基准测试的价值。鉴于对比预训练优化了具有相似捷径的大型数据集的检索，我们假设这可以解释为什么模型不需要学习表示组合信息。这一发现提出了一个自然的解决方案:成分感知硬负挖掘。我们表明，简单实现的对比学习的修改显着提高了需要理解顺序和组合性的任务的表现。\n\n## 2.Introduction\n\n例如，CLIP能区分“马在吃草”和“草在吃马”吗?，解决的问题：之前的数据集质量高，但规模相对较小;它的400个测试用例涵盖了广泛的语言现象(例如，关系、语用学、世界知识)，因此很难给出关于细粒度关系和定语能力的统计上有意义的结果。\n\n首先，作者构建了对四个数据集进行重新构建：Visual Genome Attributions and Visual Genome Relations, to test the understanding of objects’attributes and relations in complex natural scenes; and COCO Order and Flickr30k Order，to test the models’ ability to identify the correct ordering of the words in a caption (Section 2)\n\n1.Visual Genome Relation。给定一个图像和一个形式为X关系Y的组成关系，我们测试模型是否可以选择正确的顺序。具体来说，我们通过各种关系的测试用例来探索模型，以便在X关系Y和Y关系X之间进行选择，例如介词关系(例如“狗在树后面”vs“树在狗后面”)和动词(例如“马在吃草”vs“草在吃马”)。\n\n2.Visual Genome Attribution。我们测试适当地为对象赋予属性的能力。例如，我们探测模型在“蹲着的猫和打开的门”和“开着的猫和蹲着的门”之间进行选择。\n\n3.COCO Order和Flickr30k Order 。给定一个图像，我们探索模型来选择标题的正确顺序和替代方案，其中单词以系统的方式重新排序。给定给定的标题和标题本身的四种系统排列，模型是否可以“选择正确的标题”。\n\n\n### 2.1 为什么模型的行为像文字袋?对检索和对比预训练的批判\n\n既然vlm表现出较差的组合和顺序理解，为什么这些问题没有在以前的许多评估中出现?大多数vlm都在图像到文本的检索上进行了一致的评估，并展示了高性能。在本节中，我们将演示为什么检索可以是不完整的，无论是作为评估还是作为目标。我们首先表明，在不使用顺序或成分信息的情况下，模型可以很好地在现有的大规模数据集上进行文本图像检索评估。因此，缺乏组合和顺序信息的问题自然被高性能所掩盖。接下来，我们讨论了大型数据集上的对比预训练与检索任务之间的联系，并认为模型可能没有学习组合和顺序的动机。\n\n实验证明，模型采用了捷径策略，并不理解每句话的含义，只是理解每句话中单词的含义。\n\n\n### 2.2 解决方案\n\n1.生成负面的caption\n\n2.将原图像替换成类似的图像","tags":[],"folderPathname":"/Computer Vision/multi-modal/CLIP衍生领域/Reasoning","data":{},"createdAt":"2024-07-13T09:33:15.768Z","updatedAt":"2024-07-14T10:50:52.698Z","trashed":false,"_rev":"SQXGs0k_P"}