{"_id":"note:p82pRHMf0P","title":"VLDet","content":"# VLDet 论文阅读笔记\n\n> Lin C, Sun P, Jiang Y, et al. Learning object-language alignments for open-vocabulary object detection[J]. arXiv preprint arXiv:2211.14843, 2022.\n\n## 1.Abstract\n\n现有的对象检测方法被昂贵的标记数据限制在固定的词汇表中。当处理新的类别时，必须使用更多的边界框注释对模型进行重新训练。自然语言监督因其无需注释的属性和更广泛的对象概念而成为一种有吸引力的替代方案。然而，从语言中学习开放词汇表对象检测是具有挑战性的，因为图像-文本对不包含细粒度的对象-语言对齐。以前的解决方案要么依赖于昂贵的基础注释，要么依赖于提炼面向分类的视觉模型。在本文中，我们提出了一种新的开放词汇表目标检测框架，该框架直接从图像-文本对数据中学习。我们将对象语言对齐表述为一组图像区域特征和一组词嵌入之间的一组匹配问题。它使我们能够以一种非常简单和有效的方式训练图像-文本对上的开放词汇对象检测器。在COCO和L VIS两个基准数据集上进行的大量实验表明，我们在新类别上的性能优于竞争方法，例如在COCO上实现了32.0%的mAP，在L VIS上实现了21.7%的mask mAP。\n\n## 2.Method\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Detect%20and%20Segment/VLDet/pic1.jpg?raw=true)\n\n这个方法就是将Region Proposal与名词（对，名词）进行二部匹配实现开放世界的目标检测。与多模态的感觉有点不太一样。","tags":[],"folderPathname":"/Computer Vision/Detection","data":{},"createdAt":"2024-04-23T08:19:36.427Z","updatedAt":"2024-04-23T08:38:23.151Z","trashed":false,"_rev":"kjHv4pyCy"}