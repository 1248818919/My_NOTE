{"_id":"note:DeyhmvTGNw","title":"DETR","content":"# DETR 论文阅读笔记\n\n>Carion N, Massa F, Synnaeve G, et al. End-to-end object detection with transformers[C]//European conference on computer vision. Cham: Springer International Publishing, 2020: 213-229.\n\n## 1.Introduction\n\n目前detection任务都是通过在大量的提议，锚框和窗口中心定义代理回归和分类任务，这就导致了他们的性能很容易受到后处理步骤的影响（后处理用来剔除大量重复的boxes），比如通过锚集的设计和将目标框分配给锚的启发式方法。目前端到端的思路很流行并且也取得了巨大的成功，但还没有在detection领域内普及。然后作者就提出了DETR，通过删除多个手工设计的组件来简化检测流程，这些组件编码先验知识，如空间锚定或非最大抑制。\n\n![pic1](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/DETR/pic1.jpg?raw=true)\n\n## 2.Related Work\n\n### 2.1 Set Prediction\n\n没有规范的深度学习模型可以直接预测集合。基本的集合预测任务是多标签分类，其中基线方法，1 -vs-rest，不适用于诸如检测元素之间存在底层结构的问题(即，几乎相同的盒子)。所以第一个困难就是避免重复，但是现在方法大都以靠后处理，对于set prediction来说应该是无需后处理的，他们需要全局推理方案来模拟所有预测元素之间的相互作用，以避免冗余。对于恒定大小的集合预测，密集的全连接网络是足够的，但成本很高。一般的方法是使用自回归序列模型，如循环神经网络，在所有情况下，损失函数通过预测的排列应该是不变的。\n\n## 3.DETR Model\n\n### 3.1 Object detection set prediction loss\n\n在通过解码器的单次传递中，DETR推断出固定大小的$N$个预测集，其中$N$被设置为明显大于图像中典型对象的数量。训练的主要困难之一是根据真实情况对预测对象(类别、位置、大小)进行评分。\n\n定义预测结果为$\\hat{y}=\\{\\hat{y}_i\\}_{i=1}^N$,$y$是gt数量，然后给$y$进行padding填充到和$\\hat{y}$一样的大小。损失函数如下，其中$\\mathcal{L}_{match}$表示配对成本，该公式由匈牙利算法进行优化。\n\n$$\n\\hat{\\sigma}=\\arg\\min_{\\sigma\\in\\mathfrak{S}_N}\\sum_i\\mathcal{L}_{\\text{match}} ( y _ i , \\hat { y }_{\\sigma(i)}),\n$$\n\n匹配成本既考虑了类预测，也考虑了预测真值盒与真实真值盒的相似性。\n\n$$\n-1_{\\{c_i\\neq\\varnothing\\}}\\hat{p}_{\\sigma(i)}(c_i)+1_{\\{c_i\\neq\\varnothing\\}}\\mathcal{L}_{\\mathrm{box}}(b_i,\\hat{b}_{\\sigma(i)})\n$$\n\n在获得配对后，就是要计算真正的损失\n\n$$\n\\mathcal{L}_\\text{Hungarian}{ ( y , \\hat { y })}=\\sum_{i=1}^N\\left[-\\log\\hat{p}_{\\hat{\\sigma}(i)}(c_i)+1_{\\{c_i\\neq\\varnothing\\}}\\mathcal{L}_{\\mathrm{box}}(b_i,\\hat{b}_{\\hat{\\sigma}}(i))\\right]\n$$\n\nbox损失如下：\n$$\n\\lambda_\\text{iou}{ \\mathcal{L}_\\text{iou}} ( \\overline { b _ i , \\hat { b }_{\\sigma(i)}})+\\lambda_{\\text{L}1}||b_i-\\hat{b}_{\\sigma(i)}||_1\n$$\n\n### 3.2 DETR architecture\n\n![pic2](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/DETR/pic2.jpg?raw=true)\n\nBackbone. Starting from the initial image $x_{\\mathrm{img}}\\in\\mathbb{R}^{3\\times H_0\\times W_0}$ (with 3 color channels$)$, a conventional CNN backbone generates a lower-resolution activation $\\operatorname*{map}f\\in\\mathbb{R}^{C\\times H\\times W}.$ Typical values we use are $C=2048$ and $H,W=\\frac{H_0}{32},\\frac{W_0}{32}.$\n\n然后一个$1\\times1$的卷积减少通道维度，从D减少到d，特征图表示为$z_0\\in\\mathbb{R}^{d\\times H\\times W}$,然后调整到$d{\\times}HW$，然后送入到transformer中\n\n与原始变压器的不同之处在于，我们的模型在每个解码器层并行解码N个对象，而Vaswani等人[47]使用自回归模型，每次预测一个元素的输出序列。\n\n最终的预测由一个具有ReLU激活函数和隐藏维数d的3层感知器和一个线性投影层计算。坐标框是中心点，高宽四个数据组成","tags":[],"folderPathname":"/Computer Vision","data":{},"createdAt":"2024-01-15T11:18:49.274Z","updatedAt":"2024-01-16T07:32:30.249Z","trashed":false,"_rev":"BFdf-ZK5q"}