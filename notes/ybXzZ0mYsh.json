{"_id":"note:ybXzZ0mYsh","title":"A survey","content":"# Video Understanding Survey\n\n> Madan N, Møgelmose A, Modi R, et al. Foundation Models for Video Understanding: A Survey[J]. arXiv preprint arXiv:2405.03770, 2024.\n\n\n## 1.Introduction\n\n这项工作提出了用于各种视频理解任务的基础模型(vifm)的第一个全面调查。我们的调查将ViFMs分为三组:i)基于图像的ViFMs:仅在图像数据上训练。ii)基于视频的ViFMs:在培训期间利用视频数据。iii)通用基础模型(Universal Foundation Models, ufm):在预训练过程中结合各种模式(图像、视频、音频、文本)。\n\n我们根据其在时间方面的参与对视频理解任务进行了独特的分类。我们进一步提供了与每个分类任务相关的数据集和评估指标的广泛列表。\n\n我们对每个类别的ViFMs进行全面比较，分析各种研究结果。这一分析揭示了关于不同视频理解任务中最有效的vifm的宝贵见解。\n\n这项调查进一步确定了ViFMs面临的关键挑战，突出了需要进一步研究关注的开放性问题。此外，我们还讨论了ViFM发展的未来方向，为视频理解的进步铺平了道路。","tags":[],"folderPathname":"/Computer Vision/multi-modal/CLIP衍生领域/Video","data":{},"createdAt":"2024-07-30T07:52:00.029Z","updatedAt":"2024-07-30T07:53:39.536Z","trashed":false,"_rev":"f8K1QPD9f"}