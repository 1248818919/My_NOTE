{"_id":"note:kuLlgIUEaI","title":"TransTrack","content":"# TransTrack 论文阅读笔记\n\n>Sun P, Cao J, Jiang Y, et al. Transtrack: Multiple object tracking with transformer[J]. arXiv preprint arXiv:2012.15460, 2020.\n\n## 1.摘要\n\n视觉目标跟踪在视觉监控、公共安全、视频分析和人机交互等许多实际应用中都是一个至关重要的问题。当前，使用Query-Key机制的单目标跟踪方法展示出了巨大潜力，并为仍饱受模型复杂度以及计算量困扰的多目标跟踪领域提供了一种新的解决方法。因此，通过引入Query-Key机制，本文提出了一种简单而有效的多目标跟踪解决方案——TransTrack。TransTrack使用Query-Key机制的transformer架构，通过应用前一帧的目标特征作为当前帧的Query，并引入一组学习对象Query来检测新出现的对象。除此之外，TransTrack还提出了一种新的联合检测与跟踪模式，通过在一个镜头内完成目标检测和目标关联，简化了检测跟踪方法中复杂的多步设置。在MOT17和MOT20的基准测试中，TransTrack的MOTA分别达到了74.5%和64.5%，与最先进的方法相媲美。\n\n## 2.方法\n\n作者将Transformer的Encoder作为产生Key的工具，Decoder作为预测Detection box和Track box的工具，具体的Detection box用来预测当前帧中的目标，包括了上一帧中有的和没有的；Track box以上一帧中Query作为输入，用来预测上一帧中的目标。具体的结构如图所示\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/TransTrack/arch.jpg?raw=true)\n\n其中CNN作者使用的ResNet-50，目标检测中的query用的是可学习Query，和Dert一样。对于Box association，先试用KM（Kuhn-Munkres）算法，再使用IoU matching得到最终的结果。\n\n## 3.Training\n\n训练数据可能是连续的两针或者是随机相近的两帧，此外，训练数据也可以是静态图像，通过随机缩放和平移静态图像来模拟相邻帧。\n\n在TransTrack中，跟踪框和检测框是同一图像中对象框的预测。它允许我们以相同的训练损失同时训练两个解码器。训练损失如下：\n$$\n\\mathcal{L}=\\lambda_{cls}\\cdot\\mathcal{L}_{cls}+\\lambda_{L1}\\cdot\\mathcal{L}_{L1}+\\lambda_{giou}\\cdot\\mathcal{L}_{giou}\n$$\n\n其中，$\\mathcal{L_{cls}}$是focal loss表示预测分类和真实分类标签，$\\mathcal{L_{L1}}$ and $\\mathcal{L_{giou}}$ 是 L1 loss 和 generalized IoU loss。\n\n## 4.结果\n\n","tags":[],"folderPathname":"/Computer Vision/Track/single_view","data":{},"createdAt":"2024-03-21T03:50:29.504Z","updatedAt":"2024-03-21T07:46:11.527Z","trashed":false,"_rev":"mf_gPzJn4"}