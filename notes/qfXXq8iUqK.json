{"_id":"note:qfXXq8iUqK","title":"TransReID","content":"# TransReID 论文笔记\n\n>He S, Luo H, Wang P, et al. Transreid: Transformer-based object re-identification[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 15013-15022.\n\n这篇文章我泛读了，感觉类似的文章有很多，就不做过多的笔记了。\n\n## 1.Overview\n\n提取具有高鲁棒性的特征是一个十分艰难的任务。虽然基于CNN方法已经获得巨大成功，但一个CNN一次只能提取一个区域并且还要承受因卷积以及下采样而导致的细节损失。所以作者提取出了TransReID这个模型，他由JPM模块和SIE模块组成。\n\n在本文中，作者是认为卷积操作（pooling和strided convolution）导致其性能下降。作者说的本文的贡献\n- 我们首次提出了一个强大的基线，该基线利用ReID任务的纯转换器，并实现了与基于cnn的框架相当的性能。\n\n- 我们设计了一个拼图补丁模块(jigsaw patches module, JPM)，该模块由移位和补丁洗牌操作组成，有助于物体的扰动不变性和鲁棒性特征表示。\n\n- 我们引入了一种侧信息嵌入(SIE)，通过可学习的嵌入对侧信息进行编码，并被证明可以有效地减轻特征偏差。\n\n- 最终框架TransReID在包括MSMT17[46]、Market-1501[55]、DukeMTMC-reID[33]、OccludedDuke[31]、V eRi-776[25]和V ehicleID[24]在内的人员和车辆ReID基准测试中都实现了最先进的性能\n\n## 2.Model\n\n![model](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/TransReID/model.jpg?raw=true)\n\n**损失函数**\n\n交叉熵和triplet loss without label smoothing\n\n**jigsaw patch module (JPM) **\n\n1.The shift operation:$[z^1_{l−1}, z^2_{l−1}, ..., z^N_{l−1}] \\rightarrow [z^{m+1}_{l−1}, z^{m+2}_{l−1}, \\cdots, z^1_{l−1}, z^2_{l−1},\\cdots,z^{m}_{l−1}]$\n\n2.The patch shuffle operation(随机分组)\n\n** Side Information Embeddings（SIE）**\n\n作者插入可学习的1-D embeddings来保留side information。使用方法和position embedding类似。我们将相机的ID号作为一个可学习的embedding，用$S_C \\in \\mathbb{R}^{N_C \\times D}$,视点的信息用$S_V \\in \\mathbb{R}^{N_V \\times D}$，联合表示用$S_{(C,V)} \\in \\mathbb{R}^{(N_C \\times N_V) \\times D}$\n\n最后进行累加,得到最终的输入为如下的公式计算所得。\n$$\nZ_0^{'}=Z_0 + \\lambda S_{(C,V)}[r*N_V+q]\n$$","tags":[],"folderPathname":"/Computer Vision/Track/cross_view","data":{},"createdAt":"2024-01-02T06:26:15.411Z","updatedAt":"2024-01-02T07:55:26.497Z","trashed":false,"_rev":"Pzm3LqDuR"}