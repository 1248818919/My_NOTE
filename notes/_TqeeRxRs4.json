{"_id":"note:_TqeeRxRs4","title":"CVMHT","content":"# CVMHT论文笔记\n\n## 1.OverView\n\n本文主要做了以下的贡献\n\n1)结合互补的top-view图和horizontal-view图来解决多重人体跟踪问题，可以同时捕捉对象的全局轨迹和局部细节外观。\n\n2)建立了一个新的联合优化模型，跨视图和跨时间关联主题，并通过约束整数规划进行求解。\n\n3)我们收集了一个新的俯视图和水平视图视频数据集用于性能评估。\n\n## 2.Approach\n\n![how_associate](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/CVMHT/how_to_associate.jpg?raw=true)\n\n首先，作者收集了两段视频，分别来自Top-view和horizontal-view两个视角，之后，作者将其切割成了不同的clips，相当于给视频分段，一个段所含帧数较少，比如10帧。在同一个clip中，single-view关联的方式是利用IOU交并，大于阈值50%视为同一个目标。所以问题简化成了如何将不同时间，不同视角下的clip进行关联！\n\n作者将这个问题看成了一个优化问题，首先每个clip中的目标组成了一个Cluster，如图所示，我们将图中四个相邻的Cluster进行简单的标号顺时针标注$0,1,2,3$,并且定义$e^{i}_{mn}$代表从cluster $i$中第$n$个节点与cluster $i+1$中$n$节点之间二的边，他的取值是0/1。说明一下，每个cluster中的dummpy node是用来匹配哪些匹配不上的节点。优化目标如下:\n\n$argmax_{e,d}=\\sum^{3}_{i=0}(\\sum^{N_{i'}}_{n=1}c^i_{mn}*e^i_{mn}+c_0*d^i)$\n\n施加的限制条件是：\n\n1.$\\sum^{N_i}_{m=1}e^i_{mn}<=1,\\sum^{N_i'}_{n=1}e^i_{mn}<=1$(一对一)\n\n2.$e^i_{mn}+e^{i'}_{mn}+e^{i''}_{mn}<2+e^{i'''}_{mn}$(能形成一个loop，因为不可能存在view1和view2在时间t匹配不上，但是通过环又匹配上的结果出现)\n\n3.$\\sum^{N_{i'''}}_{q=1}\\sum_{m=1}^{N_i}+\\sum^{N_{i}}_{m=1}\\sum_{q=1}^{N_{i'}}+d^i=2K$(所有目标都能有匹配)\n\n### Cross-View Data Association\n\n#### 不同视角下的匹配\n\n1.Spatial reasoning\n\n$\\hat{c}=\\frac{\\sum^L_{l=1}A(T_m^l,H^l_q)}{max(|T_m|,|H_q|)}$ 其中，L代表每个clip中的长度，H，T代表不同视角下同一时间的clip，A(x,y)表示两者是否是同一个目标，是一个二值函数。\n\n2.Appearance reasoning\n\n作者设计了一个Siamese Network来计算两者的相似度，网络结果如下，通过计算output的欧氏距离，我们得到相似度得分$c^i_{qm}$,损失函数使用的是pair-based contrastive loss function。\n\n![Siamese nework](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/CVMHT/Siamese_neural_network.jpg?raw=true)\n\n#### 相同视角下的匹配\n\n1.Appearance consistency\n\n为了测量单视图被试的外观相似性，我们使用颜色直方图作为表示。我们首先计算单视图tracklet的所有目标的直方图。然后选择所有直方图的中位数作为tracklet的外观描述符。设φ (Tm)和φ (Tn)分别为轨迹子$T_m$和$T_n$的外观描述符。我们使用Histogram Intersection来计算它们之间的外观相似度:\n\n$\\hat{c}^i_{mn}=K(\\varphi(T_m),\\varphi(T_n)),i=0,2$\n\n2.Motion consistency\n我们还考虑了单视图主体关联的运动一致性。我们使用恒速运动模型来预测运动一致性，就像以前大多数的MOT跟踪方法一样。给定两个轨迹，通过运动模型可以计算出前向和后向偏差$δ_f$和$δ_b$。偏差误差$δ = α(δ_f +δ_b)$用于测量两个轨迹的差值$T_m$和$T_n$，其中α为scale因子。我们通过$\\bar{c}^i_{mn} = e−δ$将误差转换为相似度，当i = 0,2时，它取[0,1]中的值。\n\n#### 最终权值的计算\n\n$c^i_{qm} = w_1ˆ\\hat{c}^i_{qm} + (1 − w_1)\\bar{c}^i_{qm}, i = 1, 3$\n\n$c^i_{mn} = w_2ˆ\\hat{c}^i_{mn} + (1 − w_2)\\bar{c}^i_{mn}, i = 0, 2$\n\n整体的算法将以伪代码的形式给出\n![fake_code](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/CVMHT/fake_code.jpg?raw=true)\n\n## 3.Result\n![result1](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/CVMHT/result.jpg?raw=true)\n![result2](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/CVMHT/result2.jpg?raw=true)","tags":[],"folderPathname":"/Computer Vision/Track/cross_view","data":{},"createdAt":"2023-11-29T06:42:24.960Z","updatedAt":"2023-12-06T06:22:17.356Z","trashed":false,"_rev":"95HgHcQO5"}