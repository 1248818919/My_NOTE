{"_id":"note:UGIZicb1es","title":"Deformable DETR","content":"# DEFORMABLE DETR 论文阅读笔记\n\n## 1.摘要\n\n目标检测是安防监控，自动驾驶，人脸识别等领域内最为重要的一个课题。最近提出的DETR在展示良好性能的同时，消除了对许多手工设计的目标检测组件的需求。然而，由于Transformer注意力模块在处理图像特征映射时的局限性，它的收敛速度慢，特征空间分辨率有限。为了解决这些问题，本文提出了Deformable DETR，其注意力模块只关注参考目标周围的一小部分关键采样点。除此之外，在不使用FPN架构的情况下，该模块可以聚合多尺度特征，从而更好的检测微小目标。Deformable DETR可以比DETR获得更好的性能，训练次数减少10倍。在COCO基准数据集上的实验证明了本文的方法的有效性。\n\n## 2.METHOD\n\n### Deformable Attention Module\n\n给定一个特征图$x\\in\\mathbb{R}^{C\\times H\\times W}$,设$q$索引一个具有内容特征$z_q$和二维参考点$p_q$的查询元素，可变形注意力特征计算式为\n\n$$\n\\operatorname{DeformAttn}(z_q,\\boldsymbol{p}_q,\\boldsymbol{x})=\\sum_{m=1}^M\\boldsymbol{W}_m\\big[\\sum_{k=1}^KA_{mqk}\\cdot\\boldsymbol{W}_m'x(\\boldsymbol{p}_q+\\Delta\\boldsymbol{p}_{mqk})\\big]\n$$\n\n其中，其中，$m$表示注意头，$k$表示采样键数，$K$是总采样键数($k<<HW$)。上面这个版本是针对单个特征图的，如果是多尺度的话，会有另外一个版本。在代码实现中，将查询特征$z_q$馈送给$3MK$个通道的线性投影算子，其中前$2MK$个通道编码采样偏移量$∆p_{mqk}$，剩余的MK个通道馈送给softmax算子获得注意权值$A_{mqk}$\n\n对上面这个公式进行复杂度分析：\n\n- 得到坐标偏移和权重需要花$O(3N_{q}CMK)$\n- 将Query,Key进行降维需要$O(N_qC^2)$\n- 有两种对Value降维的方式：\n    - 第一种是对整个特征图进行降维，需要的计算量是$O(HWC^2)$\n    - 第二种是仅针对部分采样点进行降维，需要的计算是$O(N_qKC^2)$\n- 由于采样点是小数，所以还需要进行双线性插值，这里的复杂度是$O(5N_{q}KC)$\n\n### Multi-scale Deformable Attention Module.\n\n和上面的公式类似，这里是使用了不同的尺度的特征图进行操作。\n\n$$\n\n\\operatorname{MSDeformAtn}(z_{q},\\hat{p}_{q},\\{x^{l}\\}_{l=1}^{L})=\\sum_{m=1}^{M}\\boldsymbol{W}_{m}\\big[\\sum_{l=1}^{L}\\sum_{k=1}^{K}A_{mlqk}\\cdot\\boldsymbol{W}_{m}^{\\prime}\\boldsymbol{x}^{l}(\\phi_{l}(\\hat{p}_{q})+\\Delta\\boldsymbol{p}_{mlqk})\\big]\n\n$$\n\n其中$\\phi$表示图像的上采样操作。\n\n### Deformable Transformer Encoder\n\n这里作者多尺度特征图的来源是使用ResNet-50，具体的操作是从第三层开始取四个特征图，最后一个特征图是在第五个特征图的基础上用Conv（3×3,stride=2）的卷积得到的.\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Detect%20and%20Segment/Deformable%20DETR/pic1.jpg?raw=true)\n\n在编码器中应用多尺度可变形注意模块，输出是与输入分辨率相同的多尺度特征图。键和查询元素都是来自多尺度特征图的像素。对于每个查询像素，参考点是其本身。为了识别每个查询像素所处的特征级别，除了位置嵌入之外，我们还在特征表示中添加了一个尺度级嵌入，表示为$e_l$。与固定编码的位置嵌入不同，尺度级嵌入${e_l}^L_{l=1}$是随机初始化的，并与网络共同训练。\n\n### Iterative Bounding Box Refinement\n\n每个解码器层基于前一层的预测来细化边界框。","tags":[],"folderPathname":"/Computer Vision/Detection","data":{},"createdAt":"2024-03-25T03:09:14.158Z","updatedAt":"2024-03-26T03:04:33.195Z","trashed":false,"_rev":"nwGKI8WDM"}