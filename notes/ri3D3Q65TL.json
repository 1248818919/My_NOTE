{"_id":"note:ri3D3Q65TL","title":"Cascade-CLIP","content":"# Cascade-CLIP\n\n> Li Y, Li Z Y, Zeng Q, et al. Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation[J]. arxiv preprint arxiv:2406.00670, 2024.\n\n## 1.Introduction\n\n针对传统的将多个不同的尺度的特征图进行融合会导致zero-shot能力变差的问题，本文提出了一种新的多尺度特征图聚合方式，以实现语义分割的任务。\n\n> 这里进行评注一下，Zegclip:Towards adapting clip for zero-shot semantic segmentation.是一篇单阶段的语义分割论文，值得进行查阅。\n\n论文写法学习\n> 本文首先介绍了什么是语义分割（一句话），三句话介绍语义分割中zero-shot的问题，三句话介绍了CLIP模型对于zero-shot提供了新的解决方案，然后介绍双阶段，单阶段的基于CLIP模型的语义分割模型的优缺点，然后一段话总结自己本文的工作\n\n## 2.Analysis\n\n简单地聚合多层次视觉特征会降低分割性能，因此本文提出了一种新的聚合方式。首先，作者介绍说浅层特征图与深层特征图两者相似性很低，不应该直接进行融合，如图1所示。\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/multi-modal/CLIP%E7%9A%84%E8%A1%8D%E7%94%9F%E5%88%86%E6%94%AF/Seg/Cascade-clip/pic3.jpg?raw=true)\n\n然后作者提出了一种新的进行多层次聚合的方式，称之为Neighborhood Gaussian aggregation(NGA),并设计了如图2所示的模型图\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/multi-modal/CLIP%E7%9A%84%E8%A1%8D%E7%94%9F%E5%88%86%E6%94%AF/Seg/Cascade-clip/pic2.jpg?raw=true)\n\n","tags":[],"folderPathname":"/Computer Vision/multi-modal/CLIP衍生领域/Seg","data":{},"createdAt":"2024-06-08T07:39:42.964Z","updatedAt":"2024-06-08T09:22:24.143Z","trashed":false,"_rev":"Z8HhM23zq"}