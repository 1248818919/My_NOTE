{"_id":"note:QaSuUmskWm","title":"OSTrack","content":"# OSTrack论文笔记\n\n## 1.OverView\n\n![model](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/OSTrack/model.jpg?raw=true)\n\n目前流行的双流两阶段跟踪框架分别提取模板和搜索区域的特征，然后进行关系建模，因此提取的特征缺乏对目标的感知，目标背景的可分辨性有限。为了解决上述问题，提出了一种新的单流跟踪（OSTrack）框架，该框架通过将模板搜索图像对与双向信息流桥接来统一特征学习和关系建模。通过这种方式，可以通过相互引导来动态地提取面向判别目标的特征。由于不需要额外的重型关系建模模块，并且实现高度并行化，因此所提出的跟踪器运行速度很快。为了进一步提高推理效率，基于在单流框架中计算出的强相似性先验，提出了一种网络内候选者早期消除模块。作为一个统一的框架，OSTrack在多个基准测试上实现了最先进的性能，特别是在单次跟踪基准GOT-10k上显示了令人印象深刻的结果，即实现了73.7%的AO，将现有的最佳结果（SwinTrack）提高了4.3%。此外，我们的方法保持了良好的性能-速度折衷，并显示出更快的收敛性。\n\n## 2.Related Work\n\n我觉得下面的图挺形象的，高度代表他们模型大小。\n\n![related_work](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/OSTrack/related_work.jpg?raw=true)\n\n## 3.Approach\n\n1.首先将图像展开成seq，$z_p \\in R^{N_z×(3*P^2)}$，$N_z=H_zW_z/P^2$,然后使用一个线性层将他们的维度变成D，在加上position embeddings。这里作者还进行了消融实验，查看到底是位置编码好还是添加身份信息编码好。\n\n2.将tokens送入到具有Early Elimination module的模块中。具体的，作者将每一层的encoder可视化后进行查看，发现重点已经突出了，所以对candidate进行了选择从而减轻计算量和避免背景影响。对于template来说，作者都是选用了template最中心的那块区域所产生的token来代表这个template，从而避免背景所产生的的干扰。对于search来说，作者根据score的得分进行选择，因为得分越小越代表背景（作者这么说的）然后，作者选择前K个token来作为search region的tokens，其中保留比例定义为$ρ = k/n$\n\n3.为了将token还原成2D图像，作者还添加了pad模块，就是在对应位置进行pad。然后还原得到的特征图送入到FCN(fully convolutional network)中，FCN中有很多头，产生score map（置信度图），位置偏移图，bounding box size图。\n\n## 4.实验\n\n![res1](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/OSTrack/res.jpg?raw=true)\n\n![res2](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/OSTrack/res2.jpg?raw=true)\n\n![res3](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/OSTrack/res3.jpg?raw=true)","tags":[],"folderPathname":"/Computer Vision/Track/single_view","data":{},"createdAt":"2023-12-07T02:27:40.866Z","updatedAt":"2023-12-07T03:08:59.291Z","trashed":false,"_rev":"24FGD2gcu"}