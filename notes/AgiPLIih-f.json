{"_id":"note:AgiPLIih-f","title":"GPTv3","content":"# GPTv3 论文阅读笔记\n\nBrown T, Mann B, Ryder N, et al. Language models are few-shot learners[J]. Advances in neural information processing systems, 2020, 33: 1877-1901.\n\n## 1.Introduction\n\n最近的工作表明，通过在大量文本语料库上进行预训练，然后在特定任务上进行微调，在许多NLP任务和基准上取得了实质性的进展。但是这种方法需要特定的大量数据集和根据任务进行微调。消除这个限制是必要的，因为如下的原因：\n\n- 对于许多这样的任务来说，很难收集到一个大型的监督训练数据集，特别是当每个新任务都必须重复这个过程时。\n- 其次，利用训练数据中虚假相关性的可能性从根本上随着模型的表达能力和训练分布的狭窄而增长。大模型在小任务上表现良好并不能说明他的泛化性能优越，可能是过拟合产生的\n- 对于某些任务来说，人类并不需要过多的数据集。\n\n作者定义了Meta-learning和in-context learning两个概念，前者是说训练一个大模型，后者是说不通过梯度更新的方式，仅仅依靠对话来让模型进行学习。","tags":[],"folderPathname":"/NLP/GPT","data":{},"createdAt":"2024-01-10T02:33:08.102Z","updatedAt":"2024-01-10T03:27:26.766Z","trashed":false,"_rev":"FmOYmv643"}