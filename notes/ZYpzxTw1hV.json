{"_id":"note:ZYpzxTw1hV","title":"CatLIP","content":"# CatLIP 论文阅读笔记\n\n> Mehta S, Horton M, Faghri F, et al. CatLIP: CLIP-level Visual Recognition Accuracy with 2.7 x Faster Pre-training on Web-scale Image-Text Data[J]. arXiv preprint arXiv:2404.15653, 2024.\n\n## 1.Abstract\n\n对比学习已经成为一种变革性的方法，通过图像和文本嵌入的对齐来学习有效的视觉表征。然而，图像和文本对对比损失的两两相似度计算带来了计算上的挑战。本文提出了一种基于web规模图像文本数据的视觉模型弱监督预训练方法。该方法将图像-文本数据的预训练重构为分类任务。因此，它消除了对比损失中两两相似度计算的需要，与在web规模数据上的对比学习相比，在训练速度上实现了2.7倍的显著加速。通过广泛的实验，跨越不同的视觉任务，包括检测和分割，我们证明了该方法保持了较高的表示质量。\n\n## 2.Method","tags":[],"folderPathname":"/Computer Vision/Detection","data":{},"createdAt":"2024-05-04T01:45:03.294Z","updatedAt":"2024-05-04T01:47:04.846Z","trashed":false,"_rev":"SKAqR47kF"}