{"_id":"note:MTSuPkUPip","title":"SAFA","content":"# SAFA论文笔记\n\n> Shi Y, Liu L, Yu X, et al. Spatial-aware feature aggregation for image based cross-view geo-localization[J]. Advances in Neural Information Processing Systems, 2019, 32.\n\n## 1.Overview\n\n传统的深度网络通常将地理定位作为一个度量嵌入任务，在低召回率方面表现不佳。其中一个关键原因是两种视图模式之间的巨大差异，即地面视图与空中/卫星视图。它们不仅表现出非常不同的视觉外观，而且具有独特的几何结构。现有的深度方法忽略了这些外观和几何差异，而是使用蛮力训练程序，导致性能较差。\n\n第一步是应用常规的极坐标变换来扭曲航拍图像，使其域更接近地面全景。请注意，极变换作为一种纯粹的几何变换与场景内容无关，因此不能使两个域完全对齐。然后，我们增加了后续的空间注意机制，使相应的深度特征在嵌入空间中更接近。为了提高特征表示的鲁棒性，我们引入了一种通过学习多个空间嵌入的特征聚合策略。通过上述两步方法，我们实现了更具判别性的深度表示，使跨视图地理定位更加准确。\n\n## 2.Introduce and Related work\n\n![model](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Geo-localization/SAFA/visualization.jpg?raw=true)\n\n航空图像中物体的位置与其对应的地面图像中的物体位置具有很强的空间关系。此外，物体之间的相对位置也为交叉视图像匹配提供了关键线索。\n\n通过探索场景的这种几何构型，可以显著减少跨视图像匹配问题的模糊性，这是该论文的关键思想，以下是本文的创新点：\n\n- 我们提出了一种新的管道来解决跨视图地理定位问题。我们首先利用地面和航空图像域之间的几何对应关系，通过极变换显式地对齐这两个域，使网络能够专注于学习详细的场景相关特征对应关系。\n\n- 我们提出了一个空间感知的注意模块来根据特征位置重新加权特征。由于我们的方法将物体特征之间的相对位置嵌入到图像描述符中，因此我们的描述符更具判别性。\n\n- 我们进行了广泛的实验，证实我们提出的方法在两个标准交叉视图基准数据集上显著优于最先进的方法。与2018年提出的CVM-Net相比，我们的方法在top-1召回率方面实现了近4倍的提高。\n\n## 3.Method\n\n### 3.1 Polar Transform\n\n具体推导如下\n\n![s]()","tags":[],"folderPathname":"/Computer Vision/Geo-localization","data":{},"createdAt":"2023-12-26T03:33:25.320Z","updatedAt":"2023-12-26T07:16:54.966Z","trashed":false,"_rev":"w_RIyOVz1"}