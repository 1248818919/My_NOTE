{"_id":"note:MTSuPkUPip","title":"SAFA","content":"# SAFA论文笔记\n\n> Shi Y, Liu L, Yu X, et al. Spatial-aware feature aggregation for image based cross-view geo-localization[J]. Advances in Neural Information Processing Systems, 2019, 32.\n\n## 1.Overview\n\n传统的深度网络通常将地理定位作为一个度量嵌入任务，在低召回率方面表现不佳。其中一个关键原因是两种视图模式之间的巨大差异，即地面视图与空中/卫星视图。它们不仅表现出非常不同的视觉外观，而且具有独特的几何结构。现有的深度方法忽略了这些外观和几何差异，而是使用蛮力训练程序，导致性能较差。\n\n第一步是应用常规的极坐标变换来扭曲航拍图像，使其域更接近地面全景。请注意，极变换作为一种纯粹的几何变换与场景内容无关，因此不能使两个域完全对齐。然后，我们增加了后续的空间注意机制，使相应的深度特征在嵌入空间中更接近。为了提高特征表示的鲁棒性，我们引入了一种通过学习多个空间嵌入的特征聚合策略。通过上述两步方法，我们实现了更具判别性的深度表示，使跨视图地理定位更加准确。\n\n## 2.Introduce and Related work\n\n![model]()","tags":[],"folderPathname":"/Computer Vision/Geo-localization","data":{},"createdAt":"2023-12-26T03:33:25.320Z","updatedAt":"2023-12-26T04:05:55.302Z","trashed":false,"_rev":"pkuZn1A_f"}