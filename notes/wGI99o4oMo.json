{"_id":"note:wGI99o4oMo","title":"Debug your model","content":"# Debug your model\n\n## 1.设置断点\n\n    def function_to_debug():\n        x = 2\n\n        # set breakpoint\n        import pdb\n\n        pdb.set_trace()\n        y = x**2\n\n## 2.快速跑一遍模型\n\nThe fast_dev_run argument in the trainer runs 5 batch of training, validation, test and prediction data through your trainer to see if there are any bugs:\n\n    trainer = Trainer(fast_dev_run=True)\n\n如果要修改跑的batch，用下面的命令\n\n    trainer = Trainer(fast_dev_run=7)\n    \n## 3.Shorten the epoch length\n\nSometimes it’s helpful to only use a fraction of your training, val, test, or predict data (or a set number of batches). For example, you can use 20% of the training set and 1% of the validation set.\n\nOn larger datasets like Imagenet, this can help you debug or test a few things faster than waiting for a full epoch.\n\n    # use only 10% of training data and 1% of val data\n    trainer = Trainer(limit_train_batches=0.1, limit_val_batches=0.01)\n\n    # use 10 batches of train and 5 batches of val\n    trainer = Trainer(limit_train_batches=10, limit_val_batches=5)\n\n## 4.Run a Sanity Check\n\nLightning runs 2 steps of validation in the beginning of training. This avoids crashing in the validation loop sometime deep into a lengthy training loop.\n\n    trainer = Trainer(num_sanity_val_steps=2)\n\n## 5.Print LightningModule weights summary\n\nWhenever the .fit() function gets called, the Trainer will print the weights summary for the LightningModule.\n\n    trainer.fit(...)\n\nthis generate a table like:\n\n      | Name  | Type        | Params\n    ----------------------------------\n    0 | net   | Sequential  | 132 K\n    1 | net.0 | Linear      | 131 K\n    2 | net.1 | BatchNorm1d | 1.0 K\n\nTo add the child modules to the summary add a ModelSummary:\n\n    from lightning.pytorch.callbacks import ModelSummary\n\n    trainer = Trainer(callbacks=[ModelSummary(max_depth=-1)])\n\nTo print the model summary if .fit() is not called:\n\n    from lightning.pytorch.utilities.model_summary import ModelSummary\n\n    model = LitModel()\n    summary = ModelSummary(model, max_depth=-1)\n    print(summary)\n\nTo turn off the autosummary use:\n\n    trainer = Trainer(enable_model_summary=False)\n\n## 6.Print input output layer dimensions\n\nAnother debugging tool is to display the intermediate input- and output sizes of all your layers by setting the example_input_array attribute in your LightningModule.\n\n    class LitModel(LightningModule):\n        def __init__(self, *args, **kwargs):\n            self.example_input_array = torch.Tensor(32, 1, 28, 28)\n输出\n\n      | Name  | Type        | Params | In sizes  | Out sizes\n    --------------------------------------------------------------\n    0 | net   | Sequential  | 132 K  | [10, 256] | [10, 512]\n    1 | net.0 | Linear      | 131 K  | [10, 256] | [10, 512]\n    2 | net.1 | BatchNorm1d | 1.0 K  | [10, 512] | [10, 512]","tags":[],"folderPathname":"/Tutorial/Pytorch_Lightning/Basic/Debug, visualize and find performance bottlenecks","data":{},"createdAt":"2024-02-22T07:41:04.456Z","updatedAt":"2024-02-22T07:58:49.738Z","trashed":false,"_rev":"ktst763cR"}