{"_id":"note:faqbnMcd_Y","title":"DHU-MMCT","content":"# DHU-MMCT论文阅读笔记\n\n> Zhang Y, Wang S, Wang Q, et al. Multi-Moving Camera Pedestrian Tracking with a New Dataset and Global Link Model[J]. arXiv preprint arXiv:2312.11035, 2023.\n\n## 1.Related Work\n\n作者这个Related Work我认为整理的挺好的。因为现在大多数的方法都是先detection，然后采用不同的方式进行association。作者将这几个阶段的所用的几种方法进行了整理。\n\n### 1.1 Detection and Embedding\n\n#### 1.1.1 Human target detection\n\n大多数MOT方法都遵循按检测跟踪的范式，因此检测是一个基本步骤。首先，Yolov3提出了锚框的目标检测方法，CenterNet提出了利用中心点进行检测的方法，DETR提出了一种基于Transformer的目标检测方法的新设计，并取得了与以前的检测器相当的结果。\n\n#### 1.1.2 Embedding feature representation\n\n在以往的工作中，传统的基于外观的嵌入特征由颜色、纹理描述符、和基于patch /local的描述符来表示。目前主流的方法通常采用卷积神经网络(cnn)获得的深度嵌入特征。DeepSORT使用在MARS数据集上预训练的简单CNN来提取嵌入的外观特征（需要重新读一下）。除此之外，其还考虑了运动模式。有人利用图神经网络，仅使用运动模式就取得了较先进的成果（有时间看看）。\n\n#### 1.1.3 Joint detection and embedding\n\n为了更好地节省计算资源，joint detection and embedding(JDE)的跟踪器通过共享的单个网络进行可共同学习的目标检测和特征嵌入。Wang等人（这个必须要看一下）提出了这样一个可以同时输出检测和相应嵌入特征的JDE模型，报告了第一个(近)实时在线MOT算法设计。（FairMoT也必须要看）\n\n### 1.2 Data Association in Tracking\n\n#### 1.2.1 Graph-aided tracking\n\n随着检测和嵌入特征的准备，执行数据关联的标准方法是使用图，其中每个检测作为一个节点，边表示它们之间可能的联系。然后可以将数据关联表示为最大流量，或者等效地表示为基于距离的固定成本或学习成本的最小成本问题。Wang等将先前建立的tracklet作为节点，并设计了一个TrackletNet来测量两个tracklet之间的连通性。这些基于图的方法需要在大型图上执行计算代价高昂的全局优化，这限制了它们在在线跟踪中的应用。\n\n#### 1.2.2 Transformer-aided tracking\n\n最近，Transformer在图像分类、检测、分割、人体姿态估计以及跟踪等各种视觉任务中取得了巨大成功。基于Transformer的MOT框架通过注意实现帧间的隐式数据关联。TransTrack和TrackFormer都涉及对象查询(负责新检测)和跟踪查询(负责跨帧跟踪对象)。\n\n#### 1.2.3 Global link in tracking\n（这一块没看过相关论文，得看一下）\n近年来，交通运输取得了很大的进步。然而，仍然存在一些挑战。例如，当对象暂时遮挡或目标显示变形时，可能会发生身份转换。为了解决这类问题，人们提出了一些强大的全局链接方法。yang等主动将不完美的轨迹分离，然后将不完美的轨迹合并通过利用外观特征拆分轨道。Wang等开发了一种由Splitter和Connector两部分组成的tracklet助推器，可以有效地解决关联误差。但上述方法依赖于外观特征，对外观方差的敏感性较高。StrongSORT提出了一种全局链接模型，称为AFLink，该模型仅利用运动信息，但性能良好。TransLink利用自注意机制，充分利用外观和运动特征，获得具有代表性的全局特征，并取得了令人满意的结果。受上述方法的启发，本文提出了一种无外观的链路模型Linker，以减少丢失的关联错误，与AFLink和TransLink相比，该模型参数更少，效率更高。\n\n### 1.3 Inter-Camera Tracking and Person Re-identification\n\n#### 1.3.1 Inter-Camera Tracking\n\nMTMC跟踪需要跨相机跟踪，即相机间跟踪(ICT)，由于放置在不同地点的不同相机通常显示不同的照明条件，视角等，因此数据关联比SCT更困难。此外，行人在不同摄像头之间的运动模式难以明确表达。Huang等首次利用贝叶斯跟踪模型，利用颜色和时空特征进行非重叠多相机跟踪。Javed等Qian等为Re-ID部分的训练设计了一个聚集损失，旨在消除不同fov之间的外观外观差异。Shim等人按照标准程序实现MTMT跟踪，即检测和特征提取，单摄像机跟踪，以及每个摄像机的轨迹的多摄像机关联。Nguyen提出了一种引入r匹配算法和高斯混合模型的MTMC跟踪系统，该系统在合成数据和真实数据中都表现出色。Hao等提出了一种新的基线交叉视图多目标跟踪方法CrossMOT，首次将联合检测和嵌入从单视图跟踪器扩展到交叉视图。\n\n#### 1.3.2 Re-identification\n\n最近，Re-ID模型被引入到MTMC跟踪中。Ristani等将Re-ID类型的三重损失函数与基于硬身份挖掘的训练过程耦合在一起，以获得Re-ID和MTMC跟踪的鲁棒外观特征。Zhang等使用对齐的Re-ID，在几个常用的数据集上超过了人类的精度，获得了单相机和多相机跟踪的外观特征。使用具有多摄像头视角特征的Re-ID数据集训练的Re-ID模型，如Market-1501、DukeMTMC-reID等，可能更适用于MTMC跟踪。Zheng等甚至结合生成对抗网络(generative adversarial network, GAN)生成数据，然后基于真实数据和生成的未标记数据，以半监督的方式学习Re-ID更具判别性的嵌入。在我们的工作中，我们首先使用单相机跟踪的检测结果，然后利用轻量级ReID模型获得多相机数据关联的判别外观特征。\n\n## 2.Method\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/MMCT/pic1.jpg?raw=true)\n\n### 2.1 Global Link of Tracklets in SCT\n\nLinker（就是该section提出的用于解决ID Switch问题的轻量级模块）的作用是将相同目标但离散的tracklet进行合并。\n\n首先，用$T=\\left\\{I_{k},x_{k},y_{k},w_{k},h_{k}\\right\\}_{k=1}^{l}$表示一个Tracklet，如果Tracklet小于N帧，就用开始帧或者结束帧进行padding。\n\n","tags":[],"folderPathname":"/Computer Vision/Track/cross_view","data":{},"createdAt":"2024-02-20T07:38:42.309Z","updatedAt":"2024-02-20T09:05:55.337Z","trashed":false,"_rev":"Yl2SolQpo"}