{"_id":"note:ezEsJP2ZMp","title":"Mtrack","content":"# Mtrack 论文阅读笔记\n\n>Yu E, Li Z, Han S. Towards discriminative representation: Multi-view trajectory contrastive learning for online multi-object tracking[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 8834-8843.\n\n## 1.Introduction\n\n多目标检测已经被研究了很久，但是仍在存在因为遮挡而导致跟踪效果不好的结果出现。作者的想法是充分利用该跟踪轨迹中的所有帧来进行跟踪。这个问题的一个可能的解决方案是使用轨迹中的所有目标表示向量来构建对比损失。由于视频中的轨迹可能包括数千个实例，因此该解决方案需要大量的计算资源，这是负担不起的。为了解决这个问题，我们提出了一种称为多视角轨迹对比学习（MTCL）的策略。在该策略中，我们首先将每条轨迹建模为向量，即轨迹中心，并建立轨迹中心记忆库（TMB）来维护这些轨迹中心。在训练过程中，该内存库中的每个轨迹中心都会动态更新。然后，我们将目标外观向量视为查询，并设计对比损失，使其更接近其对应的轨迹中心，同时远离其他轨迹中心，如图所示。第1（b）段。通过这种方式，我们的方法能够利用帧间轨迹信息，同时只消耗有限的内存。\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/Mtrack/pic1.jpg?raw=true)\n\n## 2.Methodology\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/Mtrack/pic2.jpg?raw=true)\n\n### 2.1 Learnable view sampling\n\n（1）目标的中心点可能被其他物体遮挡，如图所示。第2（b）段。在这种情况下，生成的外观向量不能反映目标的特征。\n\n（2） 仅用一个向量表示每个目标不能为对比学习算法提供足够的样本。\n\n具体的，利用heatmap获取中心点的坐标$Z^{q}=(x^{q},y^{q})$，然后使用线性层预测K组偏移量$\\triangle Z^q=Wr^q$，从而获取目标的特征$Z_i^k=\\Phi(Z^q+\\triangle Z_i^q)$,其中$\\Phi$表示所有关键点都落在2D目标框中。\n\n### 2.2 Trajectory-center memory bank\n\n假设开始的时候有$N$个轨迹，memory bank将他们都初始化为零向量$\\{c_{i}\\}_{i=1}^{N}$,每次更新都是使用相似度最低的去更新，相似度计算公式如下：\n$$\ns_i^l=\\frac{p_i^l\\cdot c_l}{\\|p_i^l\\|_2\\times\\|c_l\\|_2}\n$$\n更新的公式如下：\n$$\nc_{l}\\leftarrow\\alpha c_{l}+(1-\\alpha)p_{m}^{l}\n$$\n\n损失函数：\n$$\nL_{NCE}^k=-log\\frac{exp(\\tilde{v}_l^k\\cdot c_l)/\\tau}{\\sum_{i=0}^{N_t}exp(\\tilde{v}_l^k\\cdot c_i)/\\tau}\\\\\nL_{tcl}=\\frac{1}{N_{a}}\\sum_{k=1}^{N_{a}}L_{NCE}^{k}\\\\\nL=\\frac{1}{2}(\\frac{1}{e^{\\eta_1}}L_{det}+\\frac{1}{e^{\\eta_2}}L_{tcl}+\\eta_1+\\eta_2).\n$$\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/Mtrack/pic3.jpg?raw=true)\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/Mtrack/pic4.jpg?raw=true)\n\n### 2.3 Similarity-guided Feature Fusion\n\n推理时候更新特征也是类似的，但是有点不同。更新中的$\\beta$是一个可变的量，他取决于相似度，相似度大的权重也大，\n$$\nf_l^t=(1-\\beta)f_l^{t-1}+\\beta z_l^t\\\\\\beta^t=\\max\\{0,\\frac{1}{Q}\\sum_{i=1}^Q\\Psi_d(z_l^t,z_l^{t-i})\\}\n$$\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/SingleView/Mtrack/pic5.jpg?raw=true)","tags":[],"folderPathname":"/Computer Vision/Track/single_view","data":{},"createdAt":"2024-01-24T07:25:33.660Z","updatedAt":"2024-01-24T08:07:56.914Z","trashed":false,"_rev":"o8o4o7C64"}