{"_id":"note:DbvC-5yDGJ","title":"LSS","content":"# LSS 论文阅读笔记\n\n> Philion J, Fidler S. Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d[C]//Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIV 16. Springer International Publishing, 2020: 194-210.\n\n## 1.Abstract\n\n自动驾驶汽车的感知能力是从多个传感器中提取语义信息，并将这些信息融合到一个单一的“鸟瞰”视角坐标系中，从而供路径规划使用。本文提出一种新的端到端网络架构，其可以直接从任意数量的相机视图中提取场景的俯视图。本文方法背后的核心思想是将每个图像的特征单独“提升”到每个相机的视锥中，然后将所有视锥“分散”到光栅化的俯视图网格中。从实验结果来看，该模型不仅能够学习如何表示图像，还能够学习如何将来自所有摄像机的预测融合到场景的单个俯视图表示中，同时对校准误差具有鲁棒性。在标准的鸟瞰视角任务上，如物体分割和地图分割，该模型优于所有基线和先前的工作。为了使其能够学习路径规划的密集表示的目标，本文证明了该模型能够通过将模板轨迹“射击”到网络输出的鸟瞰成本图中来实现可解释的端到端运动规划。\n\n## 2.Method\n\n\n","tags":[],"folderPathname":"/Computer Vision/Detection","data":{},"createdAt":"2024-04-07T02:26:07.567Z","updatedAt":"2024-04-07T02:58:23.390Z","trashed":false,"_rev":"XCoE-1KPi"}