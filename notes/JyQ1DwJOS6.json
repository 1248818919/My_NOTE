{"_id":"note:JyQ1DwJOS6","title":"LMGP","content":"# LMGP 论文阅读笔记\n\n>Nguyen D M H, Henschel R, Rosenhahn B, et al. Lmgp: Lifted multicut meets geometry projections for multi-camera multi-object tracking[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 8866-8875.\n\n## 1.Introduction\n\n尽管MOT已经被研究了很多年，但是仍然有很多问题，e.g.大场景和拥挤场景下单视角跟踪的表现不佳，一个可行的方法就是采用多个相机进行跟踪检测，作者总结最近的多视角跟踪方法有两种：基于单视角的和以中心表示方法。前者的方法是单视角下产生局部轨迹，将不同视角下的进行匹配。第二种方法是每个时间下进行检测并做出一个追踪图。\n\n## 2.Method\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/LMGP/pic2.jpg?raw=true)\n\n上面是一个总的流程图，由五个步骤组成\n\n- **3D Geometry Based Pre-Clustering**\n\n需要将每一个detection的位置变成真实世界的3D位置，然后将相同目标关联起来，具体的，作者将每一个det和他附近距离小于某一个阈值的det都与另一个视角邻近区域内的目标进行代价计算，然后通过线性分配的方式，只有在这个视角下分配给那个det，然后在那个视角下分配给这个目标，我们才认为分配成功，具体的伪代码如下\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/LMGP/pic1.jpg?raw=true)\n\n如果目标物体被遮挡，作者的想法是采用已经得到的统一视角下的det，找到离目标最近，同时IOU大于阈值的作为替代\n$$\n\\mathrm{visible}(b)=\\begin{cases}\\arg\\min_{b'}\\operatorname{dist}(h(b'),h_j)\\\\\\mathrm{s.t.~}b'\\in B^{\\mathrm{time}(b),\\mathrm{cam}(b)}:\\mathrm{IoU}(b',b)\\geq0.6\\end{cases}\n$$\n$$\nC_b'=\\{b'\\in C_b:b'=\\text{visible}(b')\\}\n$$\n\n\n- **Spatial-Temporal Tracking Graph**\n\n作者将关联问题变成图的问题，节点代表轨迹，变代表关联，使用CenterTrack作为生成节点的工作，作者使用DG-Net来提取特征。对于每一个Clusters，作者还是提取了每一个det的特征，然后利用cosine函数计算相似度，然后解决线性指派问题，可能的原因是之前的指派太过粗糙。\n\n然后，为了解决遮挡等产生的IDSW问题，作者重新将CenterTrack的结果进行分割，利用神经网络预测是否需要分割，利用之前的Visible的类作为预测对象，重新进行关联\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/LMGP/pic3.jpg?raw=true)\n\n获得了切片的tracklets后，就是要计算边的权重，然后通过多割进行求解。边的权重分成三种：时间，空间和限制,\n\n$$\n\\begin{aligned}\nE_{t_{\\max}}^{t}& \\left.=\\left\\{(\\tau,\\tau'):\\begin{array}{c}\\operatorname{cam}(\\tau)=\\operatorname{cam}(\\tau'),\\\\\\operatorname{max}\\{\\operatorname{time}(\\tau')\\}-\\operatorname{min}\\{\\operatorname{time}(\\tau)\\}\\in(0,t_{max}]\\end{array}\\right.\\right\\}  \\\\\nE^{s}& \\left.=\\left\\{\\left(\\tau,\\tau^{\\prime}\\right):\\begin{array}{c}\\operatorname{cam}(\\tau)\\neq\\operatorname{cam}(\\tau^{\\prime}),\\\\\\operatorname{time}(\\tau)\\cap\\operatorname{time}(\\tau^{\\prime})\\neq\\varnothing\\end{array}\\right.\\right\\}  \\\\\nE^{c}& \\left.=\\left\\{(\\tau,\\tau^{\\prime})\\in V\\times V:\\begin{array}{c}\\mathrm{cam}(\\tau)=\\mathrm{cam}(\\tau^{\\prime}),\\\\\\mathrm{time}(\\tau)\\cap\\mathrm{time}(\\tau^{\\prime})\\neq\\emptyset\\end{array}\\right.\\right\\}. \n\\end{aligned}\n$$\n\n禁止由同一相机观察到并且具有重叠时间帧的轨迹节点通过约束边最终在同一轨迹中。其中每一条边的权重计算如下\n\n$$\n\\begin{aligned}c_{e^t}=f_{\\text{temporal}}(c_{\\text{index}}^{\\text{app}}(\\tau,\\tau'),c^{\\text{fw,t}}(\\tau,\\tau'),c^{\\text{bw,t}}(\\tau,\\tau'),\\\\ t(\\tau,\\tau'))\\\\ \\\\ c_{e^s}=f_{\\text{spatial}}(c^{\\text{fw,s}}(\\tau,\\tau'),c^{\\text{bw,s}}(\\tau,\\tau'),c^{\\text{app}}(\\tau,\\tau'),\\\\ c^{\\text{avg3D}}(\\tau,\\tau'),c^{\\text{pc}}(\\tau,\\tau'))\\\\\\end{aligned}\n$$\n\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/LMGP/pic4.jpg?raw=true)\n\n\n![](https://github.com/1248818919/My_NOTE/blob/master/assets/Computer_Vision/Track/CrossView/LMGP/pic5.jpg?raw=true)\n","tags":[],"folderPathname":"/Computer Vision/Track/cross_view","data":{},"createdAt":"2024-01-22T02:56:43.123Z","updatedAt":"2024-01-22T10:59:11.572Z","trashed":false,"_rev":"e0FEOcAec"}