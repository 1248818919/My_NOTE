{"_id":"note:m7lF0wzlHu","title":"simple-BEV","content":"# Simple BEV 阅读笔记\n\n> Harley A W, Fang Z, Li J, et al. Simple-bev: What really matters for multi-sensor bev perception?[C]//2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2023: 2759-2765.\n\n## 关键思路\n\n这个文章就是改进了之前LSS的投影办法，之前的办法是先估计深度depth，然后根据深度值进行投影。这篇文章的思路是反过来的，即首先定义一个视椎，将视椎上的每一个点投影到二维平面上，然后对其进行采样。\n\n# 关键代码\n\n    def unproject_image_to_mem(self, rgb_camB, pixB_T_camA, camB_T_camA, Z, Y, X, assert_cube=False, xyz_camA=None):\n        # rgb_camB is B x C x H x W\n        # pixB_T_camA is B x 4 x 4\n \n        # rgb lives in B pixel coords\n        # we want everything in A memory coords\n \n        # this puts each C-dim pixel in the rgb_camB\n        # along a ray in the voxelgrid\n        B, C, H, W = list(rgb_camB.shape)\n        \n        # 创建3D点云，即视椎\n        if xyz_camA is None:\n            xyz_memA = utils.basic.gridcloud3d(B, Z, Y, X, norm=False, device=pixB_T_camA.device)\n            xyz_camA = self.Mem2Ref(xyz_memA, Z, Y, X, assert_cube=assert_cube)\n         \n        # 投影到B的相机coords\n        xyz_camB = utils.geom.apply_4x4(camB_T_camA, xyz_camA)  # 输出是(6, 320000, 3)\n        z = xyz_camB[:,:,2]\n         \n        # 投影到B的像素坐标系\n        xyz_pixB = utils.geom.apply_4x4(pixB_T_camA, xyz_camA)  # 输出是(6, 320000, 3)\n        normalizer = torch.unsqueeze(xyz_pixB[:,:,2], 2)  # 输出是(6, 320000, 1)\n        EPS=1e-6\n        \n        # z = xyz_pixB[:,:,2]\n        \n        # （B,坐标点数量,3）\n        xy_pixB = xyz_pixB[:,:,:2]/torch.clamp(normalizer, min=EPS)  # 输出是(6, 320000, 2)\n        # this is B x N x 2\n        # this is the (floating point) pixel coordinate of each voxel\n        x, y = xy_pixB[:,:,0], xy_pixB[:,:,1]\n        # these are B x N\n \n        x_valid = (x>-0.5).bool() & (x<float(W-0.5)).bool()\n        y_valid = (y>-0.5).bool() & (y<float(H-0.5)).bool()\n        z_valid = (z>0.0).bool()\n        valid_mem = (x_valid & y_valid & z_valid).reshape(B, 1, Z, Y, X).float()  # 输出是(6, 1, 200, 8, 200)\n \n        if (0):\n            # handwritten version\n            values = torch.zeros([B, C, Z*Y*X], dtype=torch.float32)\n            for b in list(range(B)):\n                values[b] = utils.samp.bilinear_sample_single(rgb_camB[b], x_pixB[b], y_pixB[b])\n        else:\n            # native pytorch version\n            y_pixB, x_pixB = utils.basic.normalize_grid2d(y, x, H, W)\n            # since we want a 3d output, we need 5d tensors\n            z_pixB = torch.zeros_like(x)\n            xyz_pixB = torch.stack([x_pixB, y_pixB, z_pixB], axis=2)  # 输出是(6, 320000, 3)\n            rgb_camB = rgb_camB.unsqueeze(2)\n            xyz_pixB = torch.reshape(xyz_pixB, [B, Z, Y, X, 3])  # 输出是(6, 200, 8, 200, 3)\n            values = F.grid_sample(rgb_camB, xyz_pixB, align_corners=False)  # 输出是(6, 128, 200, 8, 200)\n \n        values = torch.reshape(values, (B, C, Z, Y, X))  # 输出是(6, 128, 200, 8, 200)\n        values = values * valid_mem\n        return values","tags":[],"folderPathname":"/Computer Vision/Track/single_view","data":{},"createdAt":"2024-04-07T06:58:47.329Z","updatedAt":"2024-04-07T07:42:15.179Z","trashed":false,"_rev":"f_QMafD1Z"}